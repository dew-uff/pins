{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, re\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bibtexparser.latexenc import string_to_latex\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "import database\n",
    "from snowballing.operations import load_work_map_all_years, work_to_bibtex, reload\n",
    "from snowballing.operations import match_bibtex_to_work\n",
    "from snowballing.approaches import get_approaches, name, wlatex_name, wcitea\n",
    "reload()\n",
    "\n",
    "all_approaches = get_approaches()\n",
    "script = [(a, m) for a, m in all_approaches if not m[\"binary\"]]\n",
    "binary = [(a, m) for a, m in all_approaches if m[\"binary\"]]\n",
    "len(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../csur/bibliography.bib') as bibtex_file:\n",
    "    bibtex_str = bibtex_file.read()\n",
    "\n",
    "matched = match_bibtex_to_work(bibtex_str.split(\"%Entries\")[-1])\n",
    "works = dict(map(reversed, matched))\n",
    "latex_name = partial(wlatex_name, works=works)\n",
    "citea = partial(wcitea, works=works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "TITLE: {tname} – Could you check if the following information is correct?\n",
    "TO: {emails}\n",
    "CC: Juliana.freire@nyu.edu; leomurta@ic.uff.br; vanessa@ic.uff.br\n",
    "\n",
    "Dear {authors},\n",
    "\n",
    "We are currently working on a survey on provenance from scripts. In the survey, we propose a taxonomy for the \n",
    "state-of-the-art approaches in this research area and we characterize the approaches accordingly. We would \n",
    "also like to include {name} in this survey{middle}\n",
    "\n",
    "To avoid any misunderstandings, we would kindly ask you to check and briefly comment on the following list \n",
    "of features. We got these features based on {papers} but want to make sure we got everything\n",
    "correctly. We would highly appreciate if you could check our classification and make corrections when needed.\n",
    "Please send your answer before {date}. This would allow us to include your comments in our paper.\n",
    "\n",
    "Please, note that this is not a competition and we do not intend to rank the included systems.\n",
    "\n",
    "Collection\n",
    "        ({annotations}) Annotations\n",
    "                Placement: ({internal}) Internal; ({external}) External\n",
    "                Extraction: ({extract_parseable}) Parseable; ({extract_execution}) Execution \n",
    "                Inclusiveness: ({inclusive}) Inclusive; ({exclusive}) Exclusive\n",
    "                Target: ({target_definition}) Definition; ({target_provenance}) Provenance\n",
    "                Necessity: ({optional}) Optional; ({mandatory}) Mandatory\n",
    "        ({execution}) Execution \n",
    "                ({passive_monitoring}) Passive Monitoring\n",
    "                ({overriding}) Overriding\n",
    "                ({post_mortem}) Post-Mortem\n",
    "                ({instrumentation}) Instrumentation\n",
    "        ({deployment}) Deployment \n",
    "                ({snapshot}) Snapshot\n",
    "                ({continuous}) Continuous\n",
    "        ({definition}) Definition \n",
    "                How: ({reading}) Reading; ({parsing}) Parsing\n",
    "                When: ({static}) Static; ({dynamic}) Dynamic\n",
    "Management\n",
    "        ({storage}) Storage:\n",
    "                ({database}) Database. Specify: {database_specify}\n",
    "                ({memory}) Transient Memory\n",
    "                ({file}) File. Specify: {file_specify}\n",
    "        ({distribution}) Distribution\n",
    "                ({local}) Local. Specify: {local_specify}\n",
    "                ({remote}) Remote. Specify: {remote_specify}\n",
    "        ({reproducibility}) Reproducibility\n",
    "        ({versioning}) Versioning\n",
    "                ({trialid}) Trial ID\n",
    "                ({sequence}) Sequence\n",
    "                ({intention}) Intention\n",
    "Analysis\n",
    "        ({query}) Query\n",
    "                ({generic}) Generic. Specify: {generic_specify}\n",
    "                ({specific}) Specific. Specify: {specific_specify}\n",
    "        ({visualization}) Visualization\n",
    "                Place: ({place_internal}) Internal; ({place_external}) External\n",
    "                Type: ({log}) Log; ({data}) Data; ({process}) Process; ({combined}) Combined\n",
    "                Completeness: ({complete}) No Summarization; ({clustering}) Clustering; ({filtering}) Filtering\n",
    "        ({diff}) Comparison:\n",
    "                ({diff_data}) Data\n",
    "                ({diff_provenance}) Provenance\n",
    "\n",
    "A glossary of the taxonomy describing each one of these categories can be found at https://joaofelipe.github.io/pins\n",
    "\n",
    "Many thanks in advance!\n",
    "\n",
    "All the best,\n",
    "João Felipe Pimentel\n",
    "\n",
    "{end}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TITLE: Astro-WISE – Could you check if the following information is correct?\n",
      "TO: Jmwebaze@gmail.com; d.r.boxhoorn@astro.rug.nl; valentyn@astro.rug.nl\n",
      "CC: Juliana.freire@nyu.edu; leomurta@ic.uff.br; vanessa@ic.uff.br\n",
      "\n",
      "Dear Johnson Mwebaze, Danny Boxhoorn, and Edwin Valentijn,\n",
      "\n",
      "We are currently working on a survey on provenance from scripts. In the survey, we propose a taxonomy for the \n",
      "state-of-the-art approaches in this research area and we characterize the approaches accordingly. We would \n",
      "also like to include Astro-WISE in this survey.\n",
      "\n",
      "To avoid any misunderstandings, we would kindly ask you to check and briefly comment on the following list \n",
      "of features. We got these features based on the Astro-WISE papers [1, 2] but want to make sure we got everything\n",
      "correctly. We would highly appreciate if you could check our classification and make corrections when needed.\n",
      "Please send your answer before December 14, 2018. This would allow us to include your comments in our paper.\n",
      "\n",
      "Please, note that this is not a competition and we do not intend to rank the included systems.\n",
      "\n",
      "Collection\n",
      "        (x) Annotations\n",
      "                Placement: (x) Internal; (  ) External\n",
      "                Extraction: (  ) Parseable; (x) Execution \n",
      "                Inclusiveness: (x) Inclusive; (  ) Exclusive\n",
      "                Target: (x) Definition; (  ) Provenance\n",
      "                Necessity: (  ) Optional; (x) Mandatory\n",
      "        (x) Execution \n",
      "                (  ) Passive Monitoring\n",
      "                (  ) Overriding\n",
      "                (  ) Post-Mortem\n",
      "                (x) Instrumentation\n",
      "        (  ) Deployment \n",
      "                (  ) Snapshot\n",
      "                (  ) Continuous\n",
      "        (x) Definition \n",
      "                How: (x) Reading; (  ) Parsing\n",
      "                When: (  ) Static; (x) Dynamic\n",
      "Management\n",
      "        (x) Storage:\n",
      "                (x) Database. Specify: Relational Database (Oracle)\n",
      "                (  ) Transient Memory\n",
      "                (  ) File. Specify: __________\n",
      "        (  ) Distribution\n",
      "                (  ) Local. Specify: __________\n",
      "                (  ) Remote. Specify: __________\n",
      "        (x) Reproducibility\n",
      "        (x) Versioning\n",
      "                (  ) Trial ID\n",
      "                (x) Sequence\n",
      "                (  ) Intention\n",
      "Analysis\n",
      "        (x) Query\n",
      "                (x) Generic. Specify: SQL\n",
      "                (x) Specific. Specify: Functions, Web\n",
      "        (x) Visualization\n",
      "                Place: (x) Internal; (  ) External\n",
      "                Type: (  ) Log; (x) Data; (  ) Process; (  ) Combined\n",
      "                Completeness: (x) No Summarization; (  ) Clustering; (  ) Filtering\n",
      "        (x) Comparison:\n",
      "                (  ) Data\n",
      "                (x) Provenance\n",
      "\n",
      "A glossary of the taxonomy describing each one of these categories can be found at https://joaofelipe.github.io/pins\n",
      "\n",
      "Many thanks in advance!\n",
      "\n",
      "All the best,\n",
      "João Felipe Pimentel\n",
      "\n",
      "References:\n",
      "[1] Mwebaze, Johnson and Boxhoorn, Danny and Valentijn, Edwin. Astro-wise: Tracing and using lineage for scientific data processing. International Conference on Network-Based Information Systems, 2009\n",
      "[2] Mwebaze, Johnson and Boxhoorn, Danny and Valentijn, Edwin. Dynamic Pipeline Changes in Scientific Data Processing. IEEE International Conference on e-Science, 2011\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../emails/0-Astro-WISE.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6d278dc4ae14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapproach\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEMPLATE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../emails/{}-{}.txt\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapproach\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEMPLATE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../emails/0-Astro-WISE.txt'"
     ]
    }
   ],
   "source": [
    "from database.groups import REPRODUCIBILITY\n",
    "from database.groups import INTERNAL, EXTERNAL, PARSEABLE, EXECUTABLE, INCLUSIVE, EXCLUSIVE\n",
    "from database.groups import MANDATORY, OPTIONAL, DEFINITION, PROVENANCE\n",
    "from database.groups import PASSIVE_MONITORING, OVERRIDING, POST_MORTEM, INSTRUMENTATION\n",
    "from database.groups import SNAPSHOT, CONTINUOUS\n",
    "from database.groups import READING, PARSING, STATIC, DYNAMIC, ASKS\n",
    "from database.groups import YES, NO\n",
    "from database.groups import NOSQL, SHADOW_FILES, LOG, GRAPH_FILE, RELATIONAL_DB, FILE, WEB\n",
    "from database.groups import FILE_SYSTEM, PACKAGE, LOGIC_FILE, INTEROPERABLE, PROPRIETARY\n",
    "from database.groups import MEMORY, SOURCE, KEY_VALUE_DB, REPOSITORY, GRAPH_DB, VCS, CONTENT_DATABASE\n",
    "from database.groups import TRIAL_ID, SEQUENCE, INTENTION, NO\n",
    "from database.groups import YES, NO, PROCESS_VIEW, DATA_VIEW, COMBINED_VIEW, LOG_VIEW\n",
    "from database.groups import CLUSTERING, FILTERING, DATA, PROVENANCE, INTEROPERABLE, PROPRIETARY\n",
    "from database.groups import INTERNAL, EXTERNAL\n",
    "\n",
    "\n",
    "storage_categories = {\n",
    "    GRAPH_DB: 'Database',\n",
    "    RELATIONAL_DB: 'Database',\n",
    "    NOSQL: 'Database',\n",
    "    MEMORY: 'Memory',\n",
    "    CONTENT_DATABASE: 'File',\n",
    "    LOG: 'File',\n",
    "    INTEROPERABLE: 'File',\n",
    "    LOGIC_FILE: 'File',\n",
    "    GRAPH_FILE: 'File',\n",
    "    PROPRIETARY: 'File',\n",
    "\n",
    "    # Binary?\n",
    "    KEY_VALUE_DB: 'Database',\n",
    "    FILE_SYSTEM: 'File',\n",
    "    PACKAGE: 'File',\n",
    "    SHADOW_FILES: 'File',\n",
    "}\n",
    "\n",
    "distribution_categories = {\n",
    "    MEMORY: 'Memory',\n",
    "    CONTENT_DATABASE: 'Local',\n",
    "    LOG: 'Local',\n",
    "    INTEROPERABLE: 'Local',\n",
    "    LOGIC_FILE: 'Local',\n",
    "    GRAPH_FILE: 'Local',\n",
    "    PROPRIETARY: 'Local',\n",
    "    SOURCE: 'Local',\n",
    "    \n",
    "    VCS: 'Remote',\n",
    "    REPOSITORY: 'Remote',\n",
    "    WEB: 'Remote',\n",
    "\n",
    "    \n",
    "    # Binary?\n",
    "    FILE_SYSTEM: 'Local',\n",
    "    PACKAGE: 'Local',\n",
    "    SHADOW_FILES: 'Local',  \n",
    "}\n",
    "\n",
    "\n",
    "def select(element, field):\n",
    "    try:\n",
    "        index = field.index(element)\n",
    "        element = field[index]\n",
    "        return \"x\"\n",
    "    except ValueError:\n",
    "        return \"  \"\n",
    "    \n",
    "def select_rev(element, categories, field):\n",
    "    for value in field:\n",
    "        if value not in categories:\n",
    "            print(value, \"not in categories for\", element, categories)\n",
    "        elif categories[value] == element:\n",
    "            yield str(value)\n",
    "    \n",
    "def find(elements, abrevs, field):\n",
    "    for element, abrev in zip(elements, abrevs):\n",
    "        try:\n",
    "            index = field.index(element)\n",
    "            if (hasattr(element, \"_star\") and element._star is not None) or abrev is None:\n",
    "                yield element\n",
    "            yield abrev\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "\n",
    "def write_authors(authors):\n",
    "    if len(authors) <= 2:\n",
    "        return \" and \".join(authors)\n",
    "    authors = list(authors)\n",
    "    return \", \".join(authors[:-1]) + \", and \" + authors[-1]\n",
    "\n",
    "def load_data(approach):\n",
    "    work = approach.work\n",
    "    \n",
    "    refs = \", \".join(map(str, range(1, len(work) + 1)))\n",
    "    references = []\n",
    "    for i, w in enumerate(work):\n",
    "        references.append(\n",
    "            \"[{}] {}. {}. {}, {}\".format(\n",
    "                i + 1, w.authors, w.name, w.place.name, w.year\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    end = \"\"\n",
    "    middle = \".\"\n",
    "    tname = aname = name(approach)\n",
    "    pname = \"the {} paper\".format(tname) + (\"s\" if len(work) > 1 else \"\")\n",
    "    if approach.approach_name == \"-\":\n",
    "        tname = \"Scripts Provenance\"\n",
    "        aname = pname = \"your paper\" + (\"s\" if len(work) > 1 else \"\")\n",
    "        aname = \"{} [{}]\".format(aname, refs)\n",
    "        middle = \":\\n\\n{}\".format(\"\\n\".join(references))\n",
    "    else:\n",
    "        end = \"References:\\n{}\".format(\"\\n\".join(references))\n",
    "        pname = \"{} [{}]\".format(pname, refs)\n",
    "    if getattr(approach, \"to\", None):\n",
    "        authors = {\n",
    "            \" \".join(reversed(author.split(\", \"))): \"\"\n",
    "            for author in approach.to.split(' and ')\n",
    "        }\n",
    "    else:\n",
    "        authors = {\n",
    "            \" \".join(reversed(author.split(\", \"))): \"\" for w in work\n",
    "            for author in w.authors.split(' and ')\n",
    "        }\n",
    "    \n",
    "   \n",
    "    return {\n",
    "        'emails': approach.emails,\n",
    "        'authors': write_authors(authors),\n",
    "        'name': aname,\n",
    "        'tname': tname,\n",
    "        'papers': pname,\n",
    "        'refs': refs,\n",
    "        'end': end,\n",
    "        'middle': middle,\n",
    "        'date': 'December 14, 2018',\n",
    "        # Collection\n",
    "        ##\n",
    "        'annotations': 'x' if meta[\"annotations\"] else '  ',\n",
    "        ### placement\n",
    "        'internal': select(INTERNAL, meta[\"annotations\"]),\n",
    "        'external': select(EXTERNAL, meta[\"annotations\"]),\n",
    "        ### extraction\n",
    "        'extract_parseable': select(PARSEABLE, meta[\"annotations\"]),\n",
    "        'extract_execution': select(EXECUTABLE, meta[\"annotations\"]),\n",
    "        ### inclusiveness\n",
    "        'inclusive': select(INCLUSIVE, meta[\"annotations\"]),\n",
    "        'exclusive': select(EXCLUSIVE, meta[\"annotations\"]),\n",
    "        ### target\n",
    "        'target_definition': select(DEFINITION, meta[\"annotations\"]),\n",
    "        'target_provenance': select(PROVENANCE, meta[\"annotations\"]),\n",
    "        ### necessity\n",
    "        'optional': select(OPTIONAL, meta[\"annotations\"]),\n",
    "        'mandatory': select(MANDATORY, meta[\"annotations\"]),\n",
    "        ##\n",
    "        'execution': 'x' if meta[\"execution\"] else '  ',\n",
    "        ###\n",
    "        'passive_monitoring': select(PASSIVE_MONITORING, meta[\"execution\"]),\n",
    "        'overriding': select(OVERRIDING, meta[\"execution\"]),\n",
    "        'post_mortem': select(POST_MORTEM, meta[\"execution\"]),\n",
    "        'instrumentation': select(INSTRUMENTATION, meta[\"execution\"]),\n",
    "        ##\n",
    "        'deployment': 'x' if meta[\"deployment\"] else '  ',\n",
    "        ###\n",
    "        'snapshot': select(SNAPSHOT, meta[\"deployment\"]),\n",
    "        'continuous': select(CONTINUOUS, meta[\"deployment\"]),\n",
    "        ##\n",
    "        'definition': 'x' if meta[\"definition\"] else '  ',\n",
    "        ### how\n",
    "        'reading': select(READING, meta[\"definition\"]),\n",
    "        'parsing': select(PARSING, meta[\"definition\"]),\n",
    "        ### when\n",
    "        'static': select(STATIC, meta[\"definition\"]),\n",
    "        'dynamic': select(DYNAMIC, meta[\"definition\"]),\n",
    "        # Management\n",
    "        ##\n",
    "        'storage': 'x' if meta[\"storage\"] else '  ',\n",
    "        ###\n",
    "        'database': select(\"Database\", list(map(storage_categories.get, meta[\"storage\"]))),\n",
    "        'database_specify': \", \".join(select_rev(\"Database\", storage_categories, meta[\"storage\"])) or \"__________\",\n",
    "        'memory': select(\"Memory\", list(map(storage_categories.get, meta[\"storage\"]))),\n",
    "        'file': select(\"File\", list(map(storage_categories.get, meta[\"storage\"]))),\n",
    "        'file_specify': \", \".join(select_rev(\"File\", storage_categories, meta[\"storage\"])) or \"__________\",\n",
    "        ##\n",
    "        'distribution': 'x' if meta[\"distribution\"] else '  ',\n",
    "        ###\n",
    "        'local': select(\"Local\", list(map(distribution_categories.get, meta[\"distribution\"]))),\n",
    "        'local_specify': \", \".join(select_rev(\"Local\", distribution_categories, meta[\"distribution\"])) or \"__________\",\n",
    "        'remote': select(\"Remote\", list(map(distribution_categories.get, meta[\"distribution\"]))),\n",
    "        'remote_specify': \", \".join(select_rev(\"Remote\", distribution_categories, meta[\"distribution\"])) or \"__________\",\n",
    "        ##\n",
    "        'reproducibility': select(REPRODUCIBILITY, meta[\"supports\"]),\n",
    "        ##\n",
    "        'versioning': 'x' if meta[\"evolution\"] != NO else '  ',\n",
    "        ###\n",
    "        'trialid': 'x' if meta[\"evolution\"] == TRIAL_ID else '  ',\n",
    "        'sequence': 'x' if meta[\"evolution\"] == SEQUENCE else '  ',\n",
    "        'intention': 'x' if meta[\"evolution\"] == INTENTION else '  ',\n",
    "        # Analysis\n",
    "        ##\n",
    "        'query':  'x' if meta[\"generic_query_text\"] or meta[\"specific_query_text\"] else '  ',\n",
    "        ###\n",
    "        'generic': 'x' if meta[\"generic_query_text\"] else '  ',\n",
    "        'generic_specify': meta[\"generic_query_text\"] or \"__________\",\n",
    "        'specific': 'x' if meta[\"specific_query_text\"] else '  ',\n",
    "        'specific_specify': meta[\"specific_query_text\"] or \"__________\",\n",
    "        ##\n",
    "        'visualization':  'x' if meta[\"visplace\"] or meta[\"visualization\"] else '  ',\n",
    "        ### Place\n",
    "        'place_internal': select(INTERNAL, meta[\"visplace\"]),\n",
    "        'place_external': select(EXTERNAL, meta[\"visplace\"]),\n",
    "        ### Type\n",
    "        'log': select(LOG_VIEW, meta[\"visualization\"]),\n",
    "        'data': select(DATA_VIEW, meta[\"visualization\"]),\n",
    "        'process': select(PROCESS_VIEW, meta[\"visualization\"]),\n",
    "        'combined': select(COMBINED_VIEW, meta[\"visualization\"]),\n",
    "        ### Completeness\n",
    "        'complete': 'x' if (meta[\"visplace\"] or meta[\"visualization\"]) and not meta[\"summarization\"] else '  ',\n",
    "        'clustering': select(CLUSTERING, meta[\"summarization\"]),\n",
    "        'filtering': select(FILTERING, meta[\"summarization\"]),\n",
    "        ##\n",
    "        'diff': 'x' if meta[\"diff\"] else '  ',\n",
    "        ###\n",
    "        'diff_data': select(DATA, meta[\"diff\"]),\n",
    "        'diff_provenance': select(PROVENANCE, meta[\"diff\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, (approach, meta) in enumerate(script):\n",
    "    data = load_data(approach)\n",
    "    print(TEMPLATE.format(**data))\n",
    "    with open(\"../../emails/{}-{}.txt\".format(i, name(approach)).replace(\"*\", \"-\"), \"w\") as f:\n",
    "        f.write(TEMPLATE.format(**data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(select(PROVENANCE, meta[\"annotations\"]) == '  ' and meta[\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
