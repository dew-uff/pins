# coding: utf-8
from snowballing.models import *
from snowballing import dbindex
dbindex.last_citation_file = dbindex.this_file(__file__)

from ..work.y1979 import valdes1979a
from ..work.y1992 import rivest1992a
from ..work.y1996 import agesen1996a
from ..work.y1997 import goldman1997a
from ..work.y1998 import agrawal1998a
from ..work.y1998 import kraiss1998a
from ..work.y1998 import sonnhammer1998a
from ..work.y2000 import abiteboul2000a
from ..work.y2000 import gansner2000a
from ..work.y2000 import garofalakis2000a
from ..work.y2001 import brandes2001a
from ..work.y2002 import milo2002a
from ..work.y2002 import wilkinson2002a
from ..work.y2004 import deelman2004b
from ..work.y2004 import aalst2004a
from ..work.y2004 import salib2004a
from ..work.y2005 import bavoil2005a
from ..work.y2005 import mcphillips2005a
from ..work.y2005 import medeiros2005a
from ..work.y2006 import callahan2006a
from ..work.y2006 import muniswamy2006a
from ..work.y2006 import bex2006a
from ..work.y2006 import dufour2006a
from ..work.y2006 import hegewald2006a
from ..work.y2006 import liu2006a
from ..work.y2006 import ludascher2006a
from ..work.y2006 import mcphillips2006a
from ..work.y2006 import sapino2006a
from ..work.y2006 import tuffery2006a
from ..work.y2006 import weijters2006a
from ..work.y2007 import gil2007a
from ..work.y2007 import taylor2007a
from ..work.y2007 import grochow2007a
from ..work.y2007 import gunther2007a
from ..work.y2007 import kinsy2007a
from ..work.y2007 import medeiros2007a
from ..work.y2007 import shields2007a
from ..work.y2007 import yaman2007a
from ..work.y2007 import zhao2007a
from ..work.y2008 import biton2008a
from ..work.y2008 import bochner2008a
from ..work.y2008 import buehrer2008a
from ..work.y2008 import consortium2008a
from ..work.y2008 import navlakha2008a
from ..work.y2008 import rahman2008a
from ..work.y2008 import tian2008a
from ..work.y2009 import bao2009a
from ..work.y2009 import bao2009b
from ..work.y2009 import lacroix2009a
from ..work.y2009 import bolz2009a
from ..work.y2009 import burstein2009a
from ..work.y2009 import cock2009a
from ..work.y2009 import gervasio2009a
from ..work.y2009 import khedker2009a
from ..work.y2009 import lonquety2009a
from ..work.y2009 import ludascher2009a
from ..work.y2009 import sun2009a
from ..work.y2010 import angelino2010a
from ..work.y2010 import goble2010a
from ..work.y2010 import goecks2010a
from ..work.y2010 import lacroix2010a
from ..work.y2010 import lou2010a
from ..work.y2010 import marciniak2010a
from ..work.y2011 import guo2011b
from ..work.y2011 import pajon2011a
from ..work.y2011 import angelino2011a
from ..work.y2011 import bao2011a
from ..work.y2011 import benzaken2011a
from ..work.y2011 import buneman2011a
from ..work.y2011 import cohen2011a
from ..work.y2011 import finn2011a
from ..work.y2011 import mates2011a
from ..work.y2011 import petersen2011a
from ..work.y2011 import roure2011a
from ..work.y2011 import zeng2011a
from ..work.y2012 import garijo2012a
from ..work.y2012 import abdelkafi2012a
from ..work.y2012 import abouelhoda2012a
from ..work.y2012 import acuna2012a
from ..work.y2012 import belhajjame2012a
from ..work.y2012 import bergmann2012a
from ..work.y2012 import bouarfa2012a
from ..work.y2012 import costa2012a
from ..work.y2012 import koster2012a
from ..work.y2012 import madeira2012a
from ..work.y2012 import silva2012a
from ..work.y2012 import strauser2012a
from ..work.y2012 import szlavik2012a
from ..work.y2013 import horta2013a
from ..work.y2013 import howe2013a
from ..work.y2013 import huq2013a
from ..work.y2013 import janga2013a
from ..work.y2013 import kudo2013a
from ..work.y2013 import perry2013a
from ..work.y2013 import xu2013a
from ..work.y2014 import chen2014a
from ..work.y2014 import claes2014a
from ..work.y2014 import cohen2014a
from ..work.y2014 import filguiera2014a
from ..work.y2014 import garcia2014a
from ..work.y2014 import johnson2014a
from ..work.y2014 import lei2014a
from ..work.y2014 import ma2014a
from ..work.y2014 import murta2014a
from ..work.y2014 import starlinger2014a
from ..work.y2015 import hanson2015a
from ..work.y2015 import khan2015a
from ..work.y2015 import pienta2015a
from ..work.y2015 import acuna2015b


DB(Citation(
    acuna2015b, abdelkafi2012a, ref="[1]",
    contexts=[
        "There are three main motivations for process mining [1] :  discovering a process, analyzing process performance, and comparing the actual process with its de nition. ",
        "Abdelka  et al.  [1] arguethat a work ow is more than its process.",
        
    ],
))

DB(Citation(
    acuna2015b, abiteboul2000a, ref="[2]",
    contexts=[
        "Although fully structured by the authority that designed the resource, they appearto the other endsemi-structuredas their structure may have desiccated over time [2].",
        
    ],
))

DB(Citation(
    acuna2015b, abouelhoda2012a, ref="[3]",
    contexts=[
        "Systems such as the cloud driven Galaxy [46] WFMS, can leverage Taverna work ows by using Tavaxy [3].",
        "Tavaxy [3] provides a repository containing versions of work ows, originally authored in Taverna or Galaxy, and which have been imported into the Tavaxy format.",
    ],
))

DB(Citation(
    acuna2015b, acuna2012a, ref="[4]",
    contexts=[
        "Issues of maintainability and extendability can restrict users from reusing existing legacy ad-hoc work ows [4].",
        "This method was used by [4] who discussed the various impactsof work ow transformation and illustrated them with a case study on the StructuralPrediction  for  pRotein  fOlding  UTility  System  (SPROUTS)  [68].",
        "In  [4],  three  ways  a  work ow's  implementation  may  become  difficult  to  under-stand are discussed:  Problems of Iterative Design, Community-Based Practices, andGeneral  Work ow  Issues.",
        "This  is  partially  due  to  the  use  ofPython that unintentionally invokes dynamic language features [4].",
        "Previously [60, 4], Lacroix et al.  proposed ProtocolDB with a two layer approach to design and record work ows",
        
    ],
))

DB(Citation(
    acuna2015b, agesen1996a, ref="[5]",
    contexts=[
        "StarKiller [89] is designedto generate equivalent C++ programs from Python source by a specialized compilerwith a type inference mechanism based on the Cartesian Product Algorithm [5].",
        "ShedSkin [36] provides similar functionality [5] but with an additional focus on optimizingmemory allocation in the generated result",
        
    ],
))

DB(Citation(
    acuna2015b, agrawal1998a, ref="[6]",
    contexts=[
        "Constructing process models was  rst presented, for logs produced by IBMFlowmark, in [6].",
    ],
))

DB(Citation(
    acuna2015b, angelino2011a, ref="[7]",
    contexts=[
        "StarFlow [8] also uses static analysis (withrun-time analysis) but acknowledges that a static dependency graph forms a supersetof all possible control  ow graphs instead of a provenance graph itself [7]",
        "Unfortunately, the  le access overhead of the default Python interpretermakes  analyzing  such  a  trace  difficult  [7].",
        
    ],
))

DB(Citation(
    acuna2015b, angelino2010a, ref="[8]",
    contexts=[
        "Star ow [8] addresses the issue of tracking provenance and data reuse in work ows authored in Python.  Star ow provides a data analysis environment at the level of Python's interactive interpreter.  Star ow takes a function view of programs - func- tions are versioned and their execution parameters recorded.  Using a combination of static analysis, dynamic analysis, and user annotations, Star ow builds a dependency graph of functions in terms of the  les and folders they use.  Based on the dependency graph, Star ow detects changes in functions or input and thus determines what functions must be reexecuted.",
        "A general  approach  would  inspect  a  work ow's  source  code  to  trackdependencies  among  code  reading  and  writing   les  (e.g.,  ProvenanceCurious  [55],Star ow [8], noWork ow [81]).",
        "StarFlow [8] also uses static analysis (withrun-time analysis) but acknowledges that a static dependency graph forms a supersetof all possible control  ow graphs instead of a provenance graph itself [7]",
        
    ],
))

DB(Citation(
    acuna2015b, bao2009a, ref="[9]",
    contexts=[
        "This was implemented in PDi View [9], an graphical application which imports work ows into a sp-work ow format, generates valid runs, and then shows the operations in di erencing them"
    ],
))

DB(Citation(
    acuna2015b, bao2009b, ref="[10]",
    contexts=[
        "Analysis  of  traces  is  also  valuable,  for  instance,  Bao  et  al.   [10]  give  a  method for di erencing executions to understand control  ow in provenance.  ",
        "When developing PDi View, Bao et al. [10] used six work ows from MyExperiment.",
    ],
))

DB(Citation(
    acuna2015b, bao2011a, ref="[11]",
    contexts=[
        "Views may be com-puted from work ows but existing tools are not guaranteed to produce views that aresound (preserve data  ow) [11, 17, 96]",
        
    ],
))

DB(Citation(
    acuna2015b, bavoil2005a, ref="[12]",
    contexts=[
        "VisTrails [12] is a data visualization platform which makes a clear distinction between process and instance results.",
        "VisTrails [12] maintains provenance for visualization results by storing the pipeline process  which  created  it",
    ],
))

DB(Citation(
    acuna2015b, belhajjame2012a, ref="[13]",
    contexts=[
        "ROs can used together with existing ontologies to capture information about a work ows basic speci cation, executions, and various annotations [13]",
    ],
))

DB(Citation(
    acuna2015b, benzaken2011a, ref="[14]",
    contexts=[
        "The Ediflow platform [14] enables the convergence of visual analytics and work ows in creating visualization processes by integration of persistent DBMS",
        "The Edi ow platform [14] enables the convergence of visual analytics and work ows in creating visualization processes by integration of persistent DBMS. A second focus is on providing a live interface between a DBMS and a visualization system to enable change propagation [14].",
    ],
))

DB(Citation(
    acuna2015b, bergmann2012a, ref="[15]",
    contexts=[
        "Another approach is to de ne a set  of  rules  for  assessing  the  similarity  of  a  work ow  and  analyzing  its  graph  like representation of nodes and edges in terms of their semantics [15]. Speci cally, [15] use this assessment for the retrieval of work ows from a repository.  One limitation of  [15]  is  that  the  authors  only  consider  the  semantics  of  the  work ow", 
    ],
))

DB(Citation(
    acuna2015b, bex2006a, ref="[16]",
    contexts=[
        "Extracting thetrue structure can enable data validation, user understanding, and provide an indexto  speed  up  queries  [47,  16].",
        "Schema  extraction  may  occur  on  small  sets  of  XML   les  (where  the  schemamust  be  generalized),  or  large  sets  (where  the  schema  must  be  kept  concise)  [16].",
        "echniques often focus on inferring a regular expression (or similar) from the semi-structured XML. iDTD [16] extracts a DTD (a legacy form of schema) using subclassesof regular expressions that can be determined with only positive examples",
        
    ],
))

DB(Citation(
    acuna2015b, biton2008a, ref="[17]",
    contexts=[
        "Views may be com-puted from work ows but existing tools are not guaranteed to produce views that aresound (preserve data  ow) [11, 17, 96]",
        
    ],
))

DB(Citation(
    acuna2015b, bochner2008a, ref="[18]",
    contexts=[
        "One way to track provenance is by enabling the user to explicitly de ne the data ow using a provenance API (e.g., [18]).  However, this is intrusive since the work ow must be engineered to use the API",
    ],
))

DB(Citation(
    acuna2015b, bolz2009a, ref="[19]",
    contexts=[
        "Due  toPython's  poor  performance  as  an  interpreted  language,  several  projects  (e.g.,  [36,19,  89])  o er  the  ability  to  transform  the  source  code  of  a  Python  program  into  aC/C++ program that may be run on a di erent platform.",
        "PyPy [19] is alternative implementationof the Python interpreter based on JIT compiler techniques;  part of this project isthe RPython (Restricted Python) tool chain which allows analysis of RPython codeand generation of code targeting C (POSIX), CLI (.NET), or Java (JVM)",
        "One approach, seen inthe use of RPython by the PyPy project [19], is to de ne a speci c subset of Pythonthat  permits  static  inference  of  the  types.",
        
    ],
))

DB(Citation(
    acuna2015b, bouarfa2012a, ref="[20]",
    contexts=[
        "Outsideof digital work ows, Bouarfa and Dankelman [20] propose mining on logs of activitiesduring surgeries",
        
    ],
))

DB(Citation(
    acuna2015b, brandes2001a, ref="[21]",
    contexts=[
        "The  graph  is  stored  in  GraphML  [21],  and  annotated  with  display  informationto enable user understanding.",
        
    ],
))

DB(Citation(
    acuna2015b, buehrer2008a, ref="[22]",
    contexts=[
        "In  [22],  the  edges  making  up  complete  bipartitesubgraphs are replaced by a node with a single edge to each subgraph node",
        
    ],
))

DB(Citation(
    acuna2015b, buneman2011a, ref="[23]",
    contexts=[
        "Angelino, E., U. Braun, D. A. Holland and D. W. Margo, \Provenance integra-tion requires reconciliation, in [23]",
        "Angelino, E., U. Braun, D. A. Holland and D. W. Margo, \Provenance integra-tion requires reconciliation, in [23]",
        
    ],
))

DB(Citation(
    acuna2015b, burstein2009a, ref="[24]",
    contexts=[
        "This was explored again in the POIROT project [24]which combines trace analysis and learning methods to deduce procedural models.",
        
    ],
))

DB(Citation(
    acuna2015b, callahan2006a, ref="[25]",
    contexts=[
        "This can be enhanced by providing better tools for iterative development (e.g., parameter sweep); a user may interact with a tree representing di erent cumulative changes [25]",
    ],
))

DB(Citation(
    acuna2015b, chen2014a, ref="[26]",
    contexts=[
        "Pevious work on analyzing and understanding data ow in dynamic languages using compile-time techniques has encountered issues stemming from the difficulty of capturing the semantics of dynamic code (e.g.,  [36, 26])",
        "Chen et al.  [26] argued thatstatic  analysis  was  insuficient  to  determine  all  dependencies  in  Python  programs",
        "AsChen et al.  [26] note, Python work ows may contain unlimited errors",
        
    ],
))

DB(Citation(
    acuna2015b, claes2014a, ref="[27]",
    contexts=[
        "Clases and Poels[27] addressed this issue with a method that uses the attributes of two logs.",
        
    ],
))

DB(Citation(
    acuna2015b, cock2009a, ref="[28]",
    contexts=[
        "In  elds like bioinformatics,  libraries like BioPython [28] are used toprovided  standard  mechanisms  to  write  and  read   les  -  with  semantic  informationlike sequence or structure",
        
    ],
))

DB(Citation(
    acuna2015b, cohen2014a, ref="[29]",
    contexts=[
        "Directly rewriting a work ow can also ad-dress complexity.  For example, use of Taverna enables application of DistillFlow [29],which  provides  methods  to  rewrite  work ows  automatically  by  eliminating  knownanti-patterns.",
        
    ],
))

DB(Citation(
    acuna2015b, cohen2011a, ref="[30]",
    contexts=[
        "Unfortunately,  repositories  may  have  a  low  population  of  work ows.    Cohen-Boulakia and Leser [30] indicated that scienti c work ow management systems themselves have not yet reached widespread acceptance",
        " Present solutions fail to provide functionality required by users:  Reuse, Search and Compare, Adaptation, Assembly, and Run Analysis [30].",
        "  A  major  issue  is  that  work ow  users  are  already  comfortable  with  existing ad-hoc methods and do not  nd the learning curve for WFMSs to be worthwhile [30]",
        "Another ongoing issue in the reuse of work ows is the dificulty of understanding of existing work ows [30, 41].",
    ],
))

DB(Citation(
    acuna2015b, consortium2008a, ref="[31]",
    contexts=[
        "Other existing systems such as BioMoby, [31] allow mainly textual searches for  services  or  service  formats,  which  are  not  able  to  return  semantically  relevant options.",
    ],
))

DB(Citation(
    acuna2015b, costa2012a, ref="[32]",
    contexts=[
        "Annotation  methods  allow comparisons (e.g., label edit distance) across di erent WFMS (or execution engines) [32].",
    ],
))

DB(Citation(
    acuna2015b, medeiros2007a, ref="[33]",
    contexts=[
        "Other extensions of this workinclude letting users  nd a model by allowing visualization with dynamic parameters[49], adding heuristics to deal with noisy logs [103], and using a genetic algorithm [33]that creates a random model and repeatedly mutates it to produce a model which can produce the log.  Instead of event logs, the process mining algorithms may alsoconsider data provenance",
        
    ],
))

DB(Citation(
    acuna2015b, roure2011a, ref="[34]",
    contexts=[
        "One way to capture a work ow (and its life cycle) is by using the the idea of Research Objects (RO) [34].",
        "MyExperiment is a social platform for storing work ows and enabling collaboration [34]",
    ],
))

DB(Citation(
    acuna2015b, deelman2004b, ref="[35]",
    contexts=[
        "WFMSs that target Grid computing environments, such as Pegasus [35], have been around for some years",
        "The input is processed with a suite of tools:HMMER (a.k.a., nmmsearch) uses probabilistic models called pro le hidden Markovmodels (pro le HMMs) [38],  SignalP uses neural networks trained on separate setsof prokaryotic and eukaryotic sequences and an hidden Markov model algorithm to identify signal peptides and their cleavage sites [85], LipoP predicts lipoproteins outof signal peptides [87], and TMHMM predicts transmembrane helices in proteins [93].",
        
    ],
))

DB(Citation(
    acuna2015b, dufour2006a, ref="[36]",
    contexts=[
        "Pevious work on analyzing and understanding data ow in dynamic languages using compile-time techniques has encountered issues stemming from the difficulty of capturing the semantics of dynamic code (e.g.,  [36, 26])",
        "Due  toPython's  poor  performance  as  an  interpreted  language,  several  projects  (e.g.,  [36,19,  89])  o er  the  ability  to  transform  the  source  code  of  a  Python  program  into  aC/C++ program that may be run on a di erent platform.",
        "ShedSkin [36] provides similar functionality [5] but with an additional focus on optimizingmemory allocation in the generated result",
        "Work  such  as  ShedSkin [36] has attempted to provide type inference functionality,  and in the process has demonstrated the issues with static analysis in Python.",
        
    ],
))

DB(Citation(
    acuna2015b, filguiera2014a, ref="[37]",
    contexts=[
        "Dispel4Py [37] is a Python library which provides methods to compose data based workflows and execute them in  various  environments.",
    ],
))

DB(Citation(
    acuna2015b, finn2011a, ref="[38]",
    contexts=[
        "The input is processed with a suite of tools:HMMER (a.k.a., nmmsearch) uses probabilistic models called pro le hidden Markovmodels (pro le HMMs) [38],  SignalP uses neural networks trained on separate setsof prokaryotic and eukaryotic sequences and an hidden Markov model algorithm to identify signal peptides and their cleavage sites [85], LipoP predicts lipoproteins outof signal peptides [87], and TMHMM predicts transmembrane helices in proteins [93].",
        
    ],
))

DB(Citation(
    acuna2015b, gansner2000a, ref="[39]",
    contexts=[
        "For visualization, Graphviz [39] is used in hierarchi-cal layout mode.",
        
    ],
))

DB(Citation(
    acuna2015b, garcia2014a, ref="[40]",
    contexts=[
        "Problematically,  for  legacy  work ows  [40]  found that  discovering  annotations  from  textual  descriptions  with  the  aid  of  ontological information  was  difficult  due  to  heterogeneity  of  work ows  and  lack  of  metadata.",
    ],
))

DB(Citation(
    acuna2015b, garijo2012a, ref="[41]",
    contexts=[
        "Another ongoing issue in the reuse of work ows is the dificulty of understanding of existing work ows [30, 41].",
        "In fact,  Garijo et al.  [41] examined updates made to work ows on MyExperiment [45] and found that over half of them were a result of either general maintenance (e.g. xing an broken external tool) or  xing bugs for continued use.",
        "Garijo et al.  [41] suggest that one way to handle thecomplexity of existing work ows is by providing a more abstract view of the compo-nents or sub-work ows within a system",
        
    ],
))

DB(Citation(
    acuna2015b, garofalakis2000a, ref="[42]",
    contexts=[
        "XStruct[52], an extension of XTRACT [42, 42], a MDL technique, uses multiple XML  lesand deduces unambiguous regular expressions for the children of each XML elemen",
        
    ],
))

DB(Citation(
    acuna2015b, gervasio2009a, ref="[43]",
    contexts=[
        "Anontology query method to infer regions of missing data ow was used for traces pro-duced by expert users which include unobservable choices or actions in [43].",
        "The secondary issue of determining what latent decisions were made or not made ina work ow's execution, dependent on input, is analogous to that of determining theunobservable  choices  made  by  a  human  operator  when  implementing  a  proceduralwork ow, a problem examined in [43]",
        
    ],
))

DB(Citation(
    acuna2015b, gil2007a, ref="[44]",
    contexts=[
        "During the 2006 Challenges of Scienti c Work ows  workshop  [44],  many  issues  were  identi ed  including  the  discovery  (for reuse),  creation,  merging  (for  reuse),  and  execution  of  work ows. ",
        " As noted in [44], work ow reuse continues to be a signi cant issue",
    ],
))

DB(Citation(
    acuna2015b, goble2010a, ref="[45]",
    contexts=[
        "In fact,  Garijo et al.  [41] examined updates made to work ows on MyExperiment [45] and found that over half of them were a result of either general maintenance (e.g. xing an broken external tool) or  xing bugs for continued use.",
    ],
))

DB(Citation(
    acuna2015b, goecks2010a, ref="[46]",
    contexts=[
        "Systems such as the cloud driven Galaxy [46] WFMS, can leverage Taverna work ows by using Tavaxy [3].",
    ],
))

DB(Citation(
    acuna2015b, goldman1997a, ref="[47]",
    contexts=[
        "Extracting thetrue structure can enable data validation, user understanding, and provide an indexto  speed  up  queries  [47,  16].",
        "One  of  the   rst  methods  to  address  this  for  semi-structured data in databases was DataGuides [47], an automaton approach to creatingand maintaining a summary of a graph-based database (Lore).",
        
    ],
))

DB(Citation(
    acuna2015b, grochow2007a, ref="[48]",
    contexts=[
        "However, graphenumeration is slow and the problem is similar to graph isomorphism, thus subgraphsare limited to around 15 nodes [48].",
        "The method in [48], uses a query rather thanenumeration approach and avoiding computation for subgraph symmetries.",
        
    ],
))

DB(Citation(
    acuna2015b, gunther2007a, ref="[49]",
    contexts=[
        "Other extensions of this workinclude letting users  nd a model by allowing visualization with dynamic parameters[49], adding heuristics to deal with noisy logs [103], and using a genetic algorithm [33]that creates a random model and repeatedly mutates it to produce a model which can produce the log.  Instead of event logs, the process mining algorithms may alsoconsider data provenance",
    ],
))

DB(Citation(
    acuna2015b, guo2011b, ref="[50]",
    contexts=[
        " IncPy [50] is a non-intrusive and low level approach to the issue of data reuse; it involves the replacement of the standard Python interpreter with one which automatically catches the result of functions as they are called.",
        "IncPy [50] provides automatic memoization (and potentially provenancetracking) at run-time and takes the approach of creating an instrumented interpreter",
        
    ],
))

DB(Citation(
    acuna2015b, hanson2015a, ref="[51]",
    contexts=[
        "asr-pipeline [51]: enables creation of phylogenetic trees",
        "The work ows were asr-pipeline [51], bacana [83], hybse-qpipeline [57], inmembrane [84], pycoevol [73], and SPROUTS [68].",
        
    ],
))

DB(Citation(
    acuna2015b, hegewald2006a, ref="[52]",
    contexts=[
        "XStruct[52], an extension of XTRACT [42, 42], a MDL technique, uses multiple XML  lesand deduces unambiguous regular expressions for the children of each XML elemen",
        
    ],
))

DB(Citation(
    acuna2015b, horta2013a, ref="[53]",
    contexts=[
        "Before, during, and after, run time, Chiron [53] stores provenance information based on the  ow of relations between work ow activities.",
    ],
))

DB(Citation(
    acuna2015b, howe2013a, ref="[54]",
    contexts=[
        "SQLShare [54] is a web based platform for doing scienti c work ow like data analysis. ",
    ],
))

DB(Citation(
    acuna2015b, huq2013a, ref="[55]",
    contexts=[
        "ProvenanceCurious [55] provides a method to extract provenance from a Python program for debugging.  Using an input Python  le, ProvenanceCurious constructs a provenance graph from the syntax of the program while interacting with the user to annotate elements with information on  le access.  The provenance graph, similar to a program dependency graph, is then re ned using a number of graph rewriting rules to propagate properties between nodes, thus making some redundant and so removable. Once a provenance graph has been extracted, ProvenanceCurious supports analyzing, and querying, the data ow of that program's execution.",
        "A general  approach  would  inspect  a  work ow's  source  code  to  trackdependencies  among  code  reading  and  writing   les  (e.g.,  ProvenanceCurious  [55],Star ow [8], noWork ow [81]).",
        
    ],
))

DB(Citation(
    acuna2015b, janga2013a, ref="[56]",
    contexts=[
        "Beyond  regular  expressions,  Janga  [56]  proposed  using  a  context  free  grammar  tomodel XML, removing dependance on structure format and allowing the extractionof schema, DTD, or other structural representations.",
        
    ],
))

DB(Citation(
    acuna2015b, johnson2014a, ref="[57]",
    contexts=[
        "hybseqpipeline [57]: a sequence assembly work ow for Illumina reads",
        "The work ows were asr-pipeline [51], bacana [83], hybse-qpipeline [57], inmembrane [84], pycoevol [73], and SPROUTS [68].",
        "hybseqpipeline [57], a sequence assembly work ow for Illumina reads,Inmembrane [84] which checks if a bacterial protein codes for a surface-exposed re-gion, miR-PREFeR [66] which predicts plant microRNA from RNA sequences, andpycoevol [73] which analyzes the coevolution of a pair of proteins.  In addition, themethod is evaluated on SPROUTS [68], a true legacy work ow not intended for pub-lic  release,  which  examines  the  impact  of  point  mutations  on  protein  stability",
        
    ],
))

DB(Citation(
    acuna2015b, khan2015a, ref="[58]",
    contexts=[
        "Khanet  al.   [58]  combine  the  idea  of  clustering  on  dense  subgraphs  with  an  informationtheoretic approach",
        
    ],
))

DB(Citation(
    acuna2015b, khedker2009a, ref="[59]",
    contexts=[
        "Many static analysis techniques for data ow inprograms have been developed (see [59] for a discussion)",
        
    ],
))

DB(Citation(
    acuna2015b, kinsy2007a, ref="[60]",
    contexts=[
        "In the ProtocolDB [60, 65] WFMS, work ows are expressed in terms of a domain ontology, where each task expresses a speci c scienti c aim.",
        "Previously [60, 4], Lacroix et al.  proposed ProtocolDB with a two layer approach to design and record work ows",
        "Mapping the data owgraph to asemantic mapwhere all tools are represented as edges in a domain ontology[100] would support the documentation of the work ow in terms of its aim expressedconceptually  as  proposed  in  [60]  and  work ow  reuse,  optimization,  etc.   [65].",
        
    ],
))

DB(Citation(
    acuna2015b, kraiss1998a, ref="[61]",
    contexts=[
        "Models produced by process mining can also aid quality of service.  Kraiss andWeikum [61] address the issue of prefetching data in a three tiered data system beingqueried by clients.",
        "The  automatondi ers  from  Markov  chains  in  [61]  by  considering  dependencies  on  when  an  eventoccurs, and allowing multiple resources to be requested at once.",
        
    ],
))

DB(Citation(
    acuna2015b, koster2012a, ref="[62]",
    contexts=[
        "snakemake [62] provides a DSL implemented in Python which gives a make le-like structure for describing scientific workflows."
    ],
))

DB(Citation(
    acuna2015b, kudo2013a, ref="[63]",
    contexts=[
        "Reducing the complexity of mined processes is also studied for business work ows.Kudo et al.  [63] introduced the notion of pseudo-hubs - elements in a mined processmodel which are produced by auxiliary events (e.g.  task completion, warning mes-sage, opening a document for a task, etc.)  and which are not needed in a process'srepresentation.   Futhermore,  a  Process  Skeletonization  method  enables  the  simpli- cation of such elements from a process by searching a process for pseudo-hubs,ranking the results, and then presenting them to a user for possible removal [63].",
        
    ],
))

DB(Citation(
    acuna2015b, lacroix2010a, ref="[64]",
    contexts=[
        "In [64], Lacroix and Aziz survey the state of the BioMoby [104] web services registry for bioinformatics.",
    ],
))

DB(Citation(
    acuna2015b, lacroix2009a, ref="[65]",
    contexts=[
        "In the ProtocolDB [60, 65] WFMS, work ows are expressed in terms of a domain ontology, where each task expresses a speci c scienti c aim.",
        "For example, in ProtocolDB [65] equivalence of work ows and tasks is realized by mapping elements to an ontology and checking for identity or subtyping of concepts",
        "Mapping the data owgraph to asemantic mapwhere all tools are represented as edges in a domain ontology[100] would support the documentation of the work ow in terms of its aim expressedconceptually  as  proposed  in  [60]  and  work ow  reuse,  optimization,  etc.   [65].",
        
    ],
))

DB(Citation(
    acuna2015b, lei2014a, ref="[66]",
    contexts=[
        "miR-PREFeR [66]: predicts plant microRNA from RNA sequences",
        "The miR-PREFeR [66] work ow relies on code which is lexically correct but contextual invalid",
        "hybseqpipeline [57], a sequence assembly work ow for Illumina reads,Inmembrane [84] which checks if a bacterial protein codes for a surface-exposed re-gion, miR-PREFeR [66] which predicts plant microRNA from RNA sequences, andpycoevol [73] which analyzes the coevolution of a pair of proteins.  In addition, themethod is evaluated on SPROUTS [68], a true legacy work ow not intended for pub-lic  release,  which  examines  the  impact  of  point  mutations  on  protein  stability",
        
    ],
))

DB(Citation(
    acuna2015b, liu2006a, ref="[67]",
    contexts=[
        "Liu et al.  [67] looked at using a Program Dependence Graph to discover similarity between programs as a way to detect plagiarism. ",
    ],
))

DB(Citation(
    acuna2015b, lonquety2009a, ref="[68]",
    contexts=[
        "This method was used by [4] who discussed the various impactsof work ow transformation and illustrated them with a case study on the StructuralPrediction  for  pRotein  fOlding  UTility  System  (SPROUTS)  [68].",
        "The SPROUTS[68] work ow loads a  le at runtime which contains information on what tools areavailable and when they may be run.",
        "The work ows were asr-pipeline [51], bacana [83], hybse-qpipeline [57], inmembrane [84], pycoevol [73], and SPROUTS [68].",
        "hybseqpipeline [57], a sequence assembly work ow for Illumina reads,Inmembrane [84] which checks if a bacterial protein codes for a surface-exposed re-gion, miR-PREFeR [66] which predicts plant microRNA from RNA sequences, andpycoevol [73] which analyzes the coevolution of a pair of proteins.  In addition, themethod is evaluated on SPROUTS [68], a true legacy work ow not intended for pub-lic  release,  which  examines  the  impact  of  point  mutations  on  protein  stability",
        
    ],
))

DB(Citation(
    acuna2015b, lou2010a, ref="[69]",
    contexts=[
        "lternatively,  the issueof concurrent work ow logs,  by using temporal dependencies and re nement is ad-dressed in [69]",
        
    ],
))

DB(Citation(
    acuna2015b, ludascher2006a, ref="[70]",
    contexts=[
        "Kepler [70], a WFMS based on the Ptolemy II system [76, 77], supports modular work ow  design  (with  IDE)  and  high  level  task  scheduling  (using  a  director/actor system).",
    ],
))

DB(Citation(
    acuna2015b, ludascher2009a, ref="[71]",
    contexts=[
        "However,  many  scienti c  work ows  are  not  implemented with a WFMS, or even a work ow framework [71].",
        "Using a general programming languages leaves the work ow designer at a disadvantage.  Such languages lack support for provenance and epeatability, while promoting  unstructured  use  of  tools  [71].   These  issues  are  especially  problematic when re-targeting a work ow for a new platform [71].",
        "In a control  ow based work ow, a dependency between tasks A and B indicates that B can start only after A has completed, i.e., it defines task order [71]",
        "In a data  ow based work ow, a similar dependency would indicate that A produces data that B consumes, i.e, it de nes a data ow [71].",
        "After preprocessing steps, scienti c work ows are typically data-driven and so best represented by a dataflow [71]",
        "In the business realm, work ows are typically based on Petri nets[71].",
    ],
))

DB(Citation(
    acuna2015b, ma2014a, ref="[72]",
    contexts=[
        "Ma et al.  [72] give a distance based measure for selecting similar work ows based on an execution time constraints.",
    ],
))

DB(Citation(
    acuna2015b, madeira2012a, ref="[73]",
    contexts=[
        "pycoevol [73]: analyzes the coevolution of proteins",
        "The work ows were asr-pipeline [51], bacana [83], hybse-qpipeline [57], inmembrane [84], pycoevol [73], and SPROUTS [68].",
        "hybseqpipeline [57], a sequence assembly work ow for Illumina reads,Inmembrane [84] which checks if a bacterial protein codes for a surface-exposed re-gion, miR-PREFeR [66] which predicts plant microRNA from RNA sequences, andpycoevol [73] which analyzes the coevolution of a pair of proteins.  In addition, themethod is evaluated on SPROUTS [68], a true legacy work ow not intended for pub-lic  release,  which  examines  the  impact  of  point  mutations  on  protein  stability",
        
    ],
))

DB(Citation(
    acuna2015b, marciniak2010a, ref="[74]",
    contexts=[
        "In [74], schemas are are summarized by ranking each element using thePageRank algorithm and eliminating those with low scores.",
        
    ],
))

DB(Citation(
    acuna2015b, mates2011a, ref="[75]",
    contexts=[
        "Beyond MyExperiment, scienti c work ow repositories tend to focus on a particular WFMS (e.g., CrowdLabs [75] for VisTrails) or work ow engine (e.g., Snakemake Work ow Repository",
    ],
))

DB(Citation(
    acuna2015b, mcphillips2005a, ref="[76]",
    contexts=[
        "Kepler [70], a WFMS based on the Ptolemy II system [76, 77], supports modular work ow  design  (with  IDE)  and  high  level  task  scheduling  (using  a  director/actor system).",
    ],
))

DB(Citation(
    acuna2015b, mcphillips2006a, ref="[77]",
    contexts=[
        "Kepler [70], a WFMS based on the Ptolemy II system [76, 77], supports modular work ow  design  (with  IDE)  and  high  level  task  scheduling  (using  a  director/actor system).",
    ],
))

DB(Citation(
    acuna2015b, medeiros2005a, ref="[78]",
    contexts=[
        "WOODSS [78] emphasizes the abstraction levels of work ow design and facilitates work ow composition and reuse.",
        "Taverna [78] is a work ow system targeting bioinformatics and web service integration",
    ],
))

DB(Citation(
    acuna2015b, milo2002a, ref="[79]",
    contexts=[
        "A more general approach is searching for frequent sub-graphs.  Unique subgraphs can be discovered by enumerating possible subgraphs andcomparing their statistical prevalence with a randomized graph [79].  H",
        
    ],
))

DB(Citation(
    acuna2015b, muniswamy2006a, ref="[80]",
    contexts=[
        "Systems such as Provenance-Aware Storage Systems (PASS) [80]implement their own mechanisms for intercepting system calls to record provenanceinformation.",
        
    ],
))

DB(Citation(
    acuna2015b, murta2014a, ref="[81]",
    contexts=[
        "Run-time techniques have been used successfully for provenance tracking (e.g., [81]) but existing results do not apply to the more general problem of work ow understanding.",
        "noWork ow [81] addresses the issue of providing a non-intrusive and systematic way to collect provenance information in a general Python program",
        "A general  approach  would  inspect  a  work ow's  source  code  to  trackdependencies  among  code  reading  and  writing   les  (e.g.,  ProvenanceCurious  [55],Star ow [8], noWork ow [81]).",
    ],
))

DB(Citation(
    acuna2015b, navlakha2008a, ref="[82]",
    contexts=[
        "Handling these graphs can cause several problems:  the graph maybe too large to store in memory,  graph algorithms may become slow,  and the vol-ume  of  information  may  prevent  understanding  [82].",
        "Insteadof subgraphs, Navlakha et al.  [82] focus on node pairs and MDL optimization.",
        
    ],
))

DB(Citation(
    acuna2015b, pajon2011a, ref="[83]",
    contexts=[
        "bacana [83]:  predicts and annotates genes in bacterial genomes"
        "The work ows were asr-pipeline [51], bacana [83], hybse-qpipeline [57], inmembrane [84], pycoevol [73], and SPROUTS [68].",
        
    ],
))

DB(Citation(
    acuna2015b, perry2013a, ref="[84]",
    contexts=[
        "inmembrane [84]: checks if a bacterial protein codes for a surface-exposed region",
        "The work ow inmembrane [84] loads a con g-uration  le based on the job parameters it receives and then loads a source  le to dynamically eval its contents.",
        "The work ows were asr-pipeline [51], bacana [83], hybse-qpipeline [57], inmembrane [84], pycoevol [73], and SPROUTS [68].",
        "hybseqpipeline [57], a sequence assembly work ow for Illumina reads,Inmembrane [84] which checks if a bacterial protein codes for a surface-exposed re-gion, miR-PREFeR [66] which predicts plant microRNA from RNA sequences, andpycoevol [73] which analyzes the coevolution of a pair of proteins.  In addition, themethod is evaluated on SPROUTS [68], a true legacy work ow not intended for pub-lic  release,  which  examines  the  impact  of  point  mutations  on  protein  stability",
        
    ],
))

DB(Citation(
    acuna2015b, petersen2011a, ref="[85]",
    contexts=[
        "The input is processed with a suite of tools:HMMER (a.k.a., nmmsearch) uses probabilistic models called pro le hidden Markovmodels (pro le HMMs) [38],  SignalP uses neural networks trained on separate setsof prokaryotic and eukaryotic sequences and an hidden Markov model algorithm to identify signal peptides and their cleavage sites [85], LipoP predicts lipoproteins outof signal peptides [87], and TMHMM predicts transmembrane helices in proteins [93].",
        
    ],
))

DB(Citation(
    acuna2015b, pienta2015a, ref="[86]",
    contexts=[
        "Recently, Pienta et al.  [86] performed an extensive survey ofmethods for making sense of graphs via algorithms, visualization, and interactivity.Cluster approaches, where groups of nodes are selected by some property, involve cre-ating super-nodes and/or super-edges representing a more complex subgraph.",
        
    ],
))

DB(Citation(
    acuna2015b, rahman2008a, ref="[87]",
    contexts=[
        "The input is processed with a suite of tools:HMMER (a.k.a., nmmsearch) uses probabilistic models called pro le hidden Markovmodels (pro le HMMs) [38],  SignalP uses neural networks trained on separate setsof prokaryotic and eukaryotic sequences and an hidden Markov model algorithm to identify signal peptides and their cleavage sites [85], LipoP predicts lipoproteins outof signal peptides [87], and TMHMM predicts transmembrane helices in proteins [93].",
        
    ],
))

DB(Citation(
    acuna2015b, rivest1992a, ref="[88]",
    contexts=[
        "The  lesystem is recordedas a snapshot of MD5 [88] hashes for each  le in the work ow's folder.",
        
    ],
))

DB(Citation(
    acuna2015b, salib2004a, ref="[89]",
    contexts=[
        "Due  toPython's  poor  performance  as  an  interpreted  language,  several  projects  (e.g.,  [36,19,  89])  o er  the  ability  to  transform  the  source  code  of  a  Python  program  into  aC/C++ program that may be run on a di erent platform.",
        "StarKiller [89] is designedto generate equivalent C++ programs from Python source by a specialized compilerwith a type inference mechanism based on the Cartesian Product Algorithm [5].",
        
    ],
))

DB(Citation(
    acuna2015b, sapino2006a, ref="[90]",
    contexts=[
        "LogO  [90]applies  this  idea  in  the  domain  of  distributed  multimedia,  where  an  automaton  islearned  from  the  trace  of  data  requested  by  a  number  of  clients.",
        
    ],
))

DB(Citation(
    acuna2015b, shields2007a, ref="[91]",
    contexts=[
        "Despite the variety of ways to use work ows, each with corresponding representations and execution engines, there two general types of work ows:  Control-driven and Data-driven [91].",
    ],
))

DB(Citation(
    acuna2015b, silva2012a, ref="[92]",
    contexts=[
        "Program  slicing  [92]  is  the  general  problem  of  determining  which  part(s)  of  aprogram e ects the value of a variable at a speci c place.",
        "his can be seen asa problem of program slicing [92], where the goal is to determine exactly the part ofthe work ow program which corresponds to an internal tool.",
        "This can be seen as a problem of program slicing [92], where theportion of a program which some variable depends on must be determined.",
        
    ],
))

DB(Citation(
    acuna2015b, sonnhammer1998a, ref="[93]",
    contexts=[
        "The input is processed with a suite of tools:HMMER (a.k.a., nmmsearch) uses probabilistic models called pro le hidden Markovmodels (pro le HMMs) [38],  SignalP uses neural networks trained on separate setsof prokaryotic and eukaryotic sequences and an hidden Markov model algorithm to identify signal peptides and their cleavage sites [85], LipoP predicts lipoproteins outof signal peptides [87], and TMHMM predicts transmembrane helices in proteins [93].",
        
    ],
))

DB(Citation(
    acuna2015b, starlinger2014a, ref="[94]",
    contexts=[
        "Work ow executions provide another way to characterize work ows but are not yet in use [94].",
        "At least in the domain of of scienti c work ows, the community lacks repositories to store provenance [94]",
        "However, as repositories grow, better mechanisms for  nding a work ow or determining its similarity to another work ow [94] (e.g. a query), are necessary.",
        "There are two main ways to compare work ows: annotation or structure [94]. ",
        " Structural methods rely on information fundamentally embedded in a work ow (e.g., graph edit distance) but su er from the NP-completeness of graph isomorphism. Many methods for comparing modules reply on labels or types [94].",
        "A comparison of techniques for determining work ow similarity on a standardized corpus shows that annotations  provide  the  best  to  way  measure  module  similarity,  provided  that  the annotations  are  well  chosen  [94].",
        "Structural  approaches  can  outperform  perform  annotation  based  on  con guration, especially for poorly annotated work ows [94]",
    ],
))

DB(Citation(
    acuna2015b, strauser2012a, ref="[95]",
    contexts=[
        "The Structural  Bioinformatics  Semantic  Map  (SBMap)  [95]  is  a  dual  level  ontology  for storing  scienti c  concepts  and  resources.  ",
        "Complementary to ProtocolDB, Strauseret al. [95] developed Semantic Map, a dual level ontology for storing scienti c conceptsand resource",
        
    ],
))

DB(Citation(
    acuna2015b, sun2009a, ref="[96]",
    contexts=[
        "Views may be com-puted from work ows but existing tools are not guaranteed to produce views that aresound (preserve data  ow) [11, 17, 96]",
        
    ],
))

DB(Citation(
    acuna2015b, szlavik2012a, ref="[97]",
    contexts=[
        "szlavik et al.  [97] determine which XML elementsare important using a probabilistic method that uses eight di erent features coveringelement topology, content, and order",
        
    ],
))

DB(Citation(
    acuna2015b, taylor2007a, ref="[98]",
    contexts=[
        "Or more recently, Triana [98] which provides a middleware based environment to construct Grid enabled work ows while allowing integration with web services.",
    ],
))

DB(Citation(
    acuna2015b, tian2008a, ref="[99]",
    contexts=[
        "Oneapproach is to cluster nodes based on attributes or common relationships [99].",
        
    ],
))

DB(Citation(
    acuna2015b, tuffery2006a, ref="[100]",
    contexts=[
        "Mapping the data owgraph to asemantic mapwhere all tools are represented as edges in a domain ontology[100] would support the documentation of the work ow in terms of its aim expressedconceptually  as  proposed  in  [60]  and  work ow  reuse,  optimization,  etc.   [65].",
        
    ],
))

DB(Citation(
    acuna2015b, valdes1979a, ref="[101]",
    contexts=[
        "Work ows are speci ed in so-called sp-work ow format, which is comprised of a sp-graph [101] annotated with information about looping and forking.",
    ],
))

DB(Citation(
    acuna2015b, aalst2004a, ref="[102]",
    contexts=[
        "The alpha algorithm by Aalst [102] provides algorithmic foundations for mininga process by determining which events succeed others",
        
    ],
))

DB(Citation(
    acuna2015b, weijters2006a, ref="[103]",
    contexts=[
        "Other extensions of this workinclude letting users  nd a model by allowing visualization with dynamic parameters[49], adding heuristics to deal with noisy logs [103], and using a genetic algorithm [33]that creates a random model and repeatedly mutates it to produce a model which can produce the log.  Instead of event logs, the process mining algorithms may alsoconsider data provenance",
    ],
))

DB(Citation(
    acuna2015b, wilkinson2002a, ref="[104]",
    contexts=[
        "In [64], Lacroix and Aziz survey the state of the BioMoby [104] web services registry for bioinformatics.",
    ],
))

DB(Citation(
    acuna2015b, xu2013a, ref="[105]",
    contexts=[
        "The execution of such programs have so few constraints that their behavior cannot be predicted and the use of specialized formalisms to deal with the situation has had little success (e.g., [105])",
        "The problem of programslicing in Python was  rst studied by Xu et al.  [105]",
        
    ],
))

DB(Citation(
    acuna2015b, yaman2007a, ref="[106]",
    contexts=[
        "For traces produced by an ex-pert using services in a medical domain, [106] presented a model merging technique tolearn repetition and branching.",
        
    ],
))

DB(Citation(
    acuna2015b, zeng2011a, ref="[107]",
    contexts=[
        "Zeng et al.  [107] propose using the provenance recordedby WFMSs to create scienti c work ow models, which could be compared with thework ow expressed in the WFMS",
        "Although the re-sults may be improved by exploiting the additional data dependencies contained inprovenance,  existing process mining tools do not use data dependency information[107].",
        
    ],
))

DB(Citation(
    acuna2015b, zhao2007a, ref="[108]",
    contexts=[
        "Swift  [108]  provides  a  scripting  language  for  describing  processes  made  of  loosely coupled and data-centric elements, together with an execution engine for distributed environments",
    ],
))
